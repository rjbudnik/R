---
title: "**Yield Trial Single Loc**"
author: "Ryan Budnik"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output: 
  html_document:
    theme: darkly
    toc: true
    toc_float:
      collapsed: true
params:
  data:
    label: "Input dataset:"
    value: yt18.csv
    input: file
  book.name:
    label: "Book Name:"
    value: CF811
    input: select
    choices: [CF811, CF812, CF813, CF814, CF815, CF821, CF822,	CF823, CF824, CF825, CF831, CF832, CF833, CF834, CF835, F83.MN.Mor.105, F83.MN.Oli.106, F83.ND.Cas.123,	F83.ND.Fes.126,	F83.ND.Oak.129,	F83.ND.Pri.130,	F83.ND.Was.131, F83.SD.Abe.143,	F83.SD.Cas.145,	F83.SD.Dim.146,	F83.SD.Wes.148,	F8C.IA.Atl.9, F8C.IA.Bod.12, F8C.IA.Cla.17,	F8C.IA.Cle.18,	F8C.IA.Dow,	F8C.IA.Est.28, F8C.IA.Gra.31,	F8C.IA.Har,	F8C.IA.Hux.33, F8C.IA.Lut.39,	F8C.IA.Rei.49, F8C.IA.Ric.50,	F8C.IA.Sla.53,	F8C.IL.Cha.161,	F8C.IL.Gen.61, F8C.IL.Har.162, F8C.IL.MtP.163, F8C.IL.Roc.74, F8C.IL.Ros.75,	F8C.IL.Ton.164,	F8C.IN.Bro.165, F8C.IN.Far.166,	F8C.MN.Bro.100,	F8C.MN.Mad.104,	F8C.MN.Pip.107,	F8C.MN.Pla.108, F8C.MN.San.111,	F8C.MN.Sle.113,	F8C.MN.StC.114,	F8C.MN.Ste.115,	F8C.MN.Wel.116, F8C.NE.Arl.132,	F8H.MB.Win,	F8I.MB.Mor,	F8I.MB.Por,	F8I.MB.War,	F8K.IA.Gri, F8K.MN.Rou.110,	F8K.NE.Tek.135,	F8K.SD.Can.144,	F8P.IL.DGr.167,	F8P.IL.Mal.169, F8P.IL.Tam.168,	F8P.PA.Lew.171,	F8P.PA.MtJ.172,	F8P.WI.Ran.170,	F8R.MN.Gly.101, F8R.MN.Rad.109,	F8R.ND.Cha.124,	F8R.ND.Don.125,	F8R.ND.Min.128,	F8T.IA.Ced.15, F8T.IA.Cre.23,	F8T.IA.Dec.24,	F8T.IA.Lak.36,	F8T.IA.Spe.54,	F8T.IL.Blo.57, F8T.IL.Mon.69,	F8T.MI.Ree.96,	F8T.MN.Alb.97,	F8T.MN.Hay.102,	F8T.MN.Jac.103, F8T.WI.Jan.149,	F8T.WI.Pla.150]
  exp:
    label: "Experiment:"
    value: C81A
    input: select
    choices: [C81A,	C81B,	C82A,	C82B,	C83A,	C83B,	R18-101, R18-102, R18-103, R18-104, R18-105, R18-106, R18-107, R18-108, R18-201, R18-202, R18-203, R18-204, R18-205, R18-206-Olivia,	R18-301,	R18-302, R18-303, R18-401, R18-402, R18-501, R18-601, R18-602, YT01P18_UE, YT02P18_E,	YT03P18_M1,	YT04P18_L1,	YT05P18_WL2, YT06P18_RE, YT07P18_RM,	YT08P18_RL,	YT09P18_D1E1,	YT10P18_D1E2,	YT11P18_D1E3,	YT12P18_D1M4, YT13P18_D2A, YT14P18_D2B,	YT15P18_D2C, YT16P18_D3, YT17P18_JE,	YT18P18_JL, YT19P18_WES, YT20P18_WLS, YT21P18_PSN, YT22P18_PSL,	YT23P18_KM,	YT24P18_KL, YT25P18_DG,	YTNL_Obs,	YTNL01,	YTNL02,	YTNL03,	YTNL04,	YTNL05,	YTNL06,	YTNL07,	YTNL08, YTNL09,	YTNL10,	YTNL11,	YTNL12]
  entry.start:
    label: "Entry Start"
    value: 1
    input: slider
    min: 1
    max: 100
    step: 1
    sep: ""
  entry.end:
    label: "Entry End"
    value: 45
    input: slider
    min: 1
    max: 100
    step: 1
    sep: ""
  year:
    label: "Year"
    value: 2018
    input: slider
    min: 2010
    max: 2030
    step: 1
    sep: ""
---

```{r logo, cache=TRUE, echo=FALSE}
htmltools::img(src = knitr::image_uri(file.path("C:", "Users", "Ryan.Ryan-PC", "Desktop", "ICIA_logo.png")), 
               alt = 'logo', 
               style = 'position:absolute; top:0; right:0; padding:10px;')
```

---


# Overview:
The following report renders a single location mixed model analysis with corresponding figures for the `r params$year`-- **`r params$exp`** Trial, at the **`r params$book.name`** location.

```{r libs, include = FALSE}
library(rmarkdown)
library(knitr)
library(dplyr)
library(agricolae)
library(nlme)
library(lme4)
library(LMERConvenienceFunctions)
library(lmerTest)
library(randomcoloR)
library(car)
library(predictmeans)
library(shiny)
library(shinythemes)
library(psych)
library(skimr)
```

Corn Coversion Factor = **8.067**

```{r setup, echo = FALSE}
###Set wd & Import CSV Dataset:
df<-read.csv("yt18.csv", header=T, na.strings=c("", " ", "NA"))

###CCF
CCF<-8.067
df <- df%>%mutate (yld = (wt*CCF))
###BCF
# BCF<-7.779
# df <- df%>%mutate (yld = (wt*BCF))

df <- df%>%mutate(yld=replace(yld, plot.discard=="Yes", NA))

###Subset data of interest:
data<-filter(df, book.name==c(params$book.name) & exp==c(params$exp), entry %in% c(params$entry.start:params$entry.end))

###View Classifications & Set Factors:
data$book.name<-factor(data$book.name)
data$exp<-factor(data$exp)
data$entry<-factor(data$entry)
data$ped.id<-factor(data$ped.id)
data$code<-factor(data$code)
data$range<-factor(data$range)
data$pass<-factor(data$pass)
data$rep<-factor(data$rep)
attach(data)

###Mean & IQRS:
max.yld <- quantile(data$yld,0.75, na.rm=TRUE) + (IQR(data$yld, na.rm=TRUE) * 1.5 )
min.yld <- quantile(data$yld,0.25, na.rm=TRUE) - (IQR(data$yld, na.rm=TRUE) * 1.5 )
avg.yld <- mean(data$yld, na.rm = TRUE)
max.wt <- quantile(data$wt,0.75, na.rm=TRUE) + (IQR(data$wt, na.rm=TRUE) * 1.5 )
min.wt <- quantile(data$wt,0.25, na.rm=TRUE) - (IQR(data$wt, na.rm=TRUE) * 1.5 )
avg.wt <- mean(data$wt, na.rm = TRUE)
```

# Data Visualization: {.tabset .tabset-fade}

## Summary

```{r summary, echo = FALSE, cols.print=8, rows.print=20, warning=FALSE}
dfNo_rec.id<-subset(data, select = -c(rec.id))
des<-describe(dfNo_rec.id, IQR=TRUE)
paged_table(des, options(scipen=999, digits=3))
```

## Aggregation

```{r aggregation, echo = FALSE, rows.print=20, warning=FALSE}
options(digits=5)
aggdf <- data.frame(aggregate(yld~entry, data=data, function(x) c(length(x))),aggregate(yld~entry, data=data, function(x) c(min(x))),aggregate(yld~entry, data=data, function(x) c(mean(x))),aggregate(yld~entry, data=data, function(x) c(max(x))))
aggdf <- aggdf[,c(1,2,4,6,8)]
colnames(aggdf)<-c("Entry", "Count", "Min", "Mean", "Max")
paged_table(aggdf)
```

## Histograms

``` {r histo.wt, echo = FALSE, fig.width=9}
histo<-hist(data$wt, breaks=seq(0,40, l=90), col="orange", main="Distribution of Weight", xlab="Weight")
abline(v = max.wt, col="red")
abline(v = avg.wt, col="red", lwd=c(3))
abline(v = min.wt, col="red")
```

```{r histo.yld, echo = FALSE, fig.width=9}
histo<-hist(data$yld, breaks=seq(0,300, l=90), col="purple", main="Distribution of Yield", xlab="Yield")
abline(v = max.yld, col="red")
abline(v = avg.yld, col="red", lwd=c(3))
abline(v = min.yld, col="red")
```

## Barplots

``` {r bar.wt, echo = FALSE, fig.width=10, fig.height=7}
palette <- randomColor(length(unique(data$entry)))
data$color <- palette[as.factor(data$entry)]
barplot(data$wt, names.arg=data$entry, ylim=c(0,40), main="Distribution of Weight", ylab="Weight", xlab="Entry", col=data$color)
abline(h = max.wt, col="red")
abline(h = avg.wt, col="red", lwd=c(3))
abline(h = min.wt, col="red")
```

``` {r bar.yld, echo = FALSE, fig.width=10, fig.height=7}
barplot(data$yld, names.arg=data$entry, ylim=c(0,300), main="Distribution of Yield", ylab="Yield", xlab="Entry", col=data$color)
abline(h = max.yld, col="red")
abline(h = avg.yld, col="red", lwd=c(3))
abline(h = min.yld, col="red")
```

## Boxplot

``` {r boxplot, echo = FALSE, fig.width=9}
Boxplot(data$yld~data$entry,id=TRUE, main="2018 Yield Across Entries", xlab="entry", ylab="Yld")
abline(h = max.yld, col="red")
abline(h = avg.yld, col="red", lwd=c(3))
abline(h = min.yld, col="red")
```

# Mixed Model Analysis: {.tabset .tabset-fade}

## Summary

**Model: Yield = Entry**

Random Effects: rep, pass(rep), range(rep)

```{r model, echo=FALSE, message=FALSE}
model1<-lmer(yld~entry + (1 | rep) + (1|rep:pass) + (1 | rep:range), data=data, REML=TRUE)
summary(model1)
```

## Random-Effects Table

```{r modelsum, echo=FALSE}
kable(ranova(model1))
```

## Predicted Means

```{r modelpredictmeans, echo=FALSE, message=FALSE}
predictmeans(model1, "entry", pairwise=FALSE, level=.25, newwd=FALSE)
```

## ANOVA Tables

Generally speaking, the smaller the *p-value*, and the larger the *F-statistic* the better the model fit and grounds for rejection of the null hypothesis.

ANOVA uses the *F-statistic* to determine whether the variability between group means is larger than the variability of the observations within the groups. If that ratio is sufficiently large, you can conclude that not all the means are equal. A low *p-value* suggests that your sample provides enough evidence that you can reject the null hypothesis for the entire population.

  + The **null hypothesis** states that the model with no independent variables fits       the data as well as your model.

  + The **alternative hypothesis** says that your model fits the data better than the      intercept-only model.


Analysis of Variance Table of **Type I** with Kenward-Roger approximation for degrees of freedom:

```{r modelanova1, echo = FALSE}
kable(anovalmer(model1))
```

**Type III** Analysis of Variance Table with Satterthwaite's method:

```{r modelanova2, echo = FALSE}
kable(anova(model1))
```

## CV & LSD

**Coefficient of Vairance (CV):**

The CV for a model aims to describe the model fit in terms of the relative sizes of the squared residuals and outcome values.  The lower the CV, the smaller the residuals relative to the predicted value.  This is suggestive of a good model fit.

The advantage of the CV is that it is unitless.  This allows CVs to be compared to each other in ways that other measures, like standard deviations or root mean squared residuals, cannot be. 

**The model with the smaller CV has predicted values that are closer to the actual values.**

```{r modelcv, echo = FALSE}
LSDer::CVer(model1)
```

**Fisher's Least Significant Differnce (LSD):**

Least significant difference is used to compare means of different treatments that have an equal number of replications. The yields must be greater than the LSD value between any two hybrids, varieties, or treatments to be considered significant. This ensures the differences are real and not because of chance or due to soil variability.

LSD values in the university tests are generally reported at (0.1) or 10% level. It means that there is a 90% chance that any one of the hybrids or varieties within the LSD value for the test could be on the top. Some test plot data are now being reported with LSD at (0.25) or 75% level, perhaps to be more inclusive.


*At 90% Confidence:*

```{r modellsd.1, echo = FALSE}
LSDer::LSDer(model1, "entry", level=0.90)
```

*At 75% Confidence:*

```{r modellsd.25, echo = FALSE}
LSDer::LSDer(model1, "entry", level=0.75)
```


# Outlier Detection: {.tabset .tabset-fade}

## Normal Q-Q Plot

QQ plot (or quantile-quantile plot) draws the correlation between a given sample and the normal distribution. A 45-degree reference line is also plotted. QQ plots are used to visually check the normality of the data.

```{r qq, echo = FALSE, warning = FALSE}
qq<-qqnorm(resid(model1))
qqline(resid(model1), col="red", lwd=c(2))
text(qq, rownames(data), cex=1.2, font=2)
```

## Cook's Distance

Cook’s distance is useful for identifying outliers in the X values (observations for predictor variables). It also shows the influence of each observation on the fitted response values. An observation with Cook’s distance larger than three times the mean Cook’s distance might be an outlier.

  + Graphical Reference Thresholds:
      1. 10/*n*-*k*-1
      2. 8/*n*-*k*-1
      3. 4/*n*-*k*-1, (**Hair et.al**,1998)
     
      where,
      
      *n* = sample size
      
      *k* = number of independent variables

```{r cook, cache=TRUE, echo = FALSE}
sample_size<-nrow(data)
Cooksd<-CookD(model1, newwd=FALSE)
abline(h = (10/(sample_size-params$entry.end-1)), col="red")
abline(h = (8/(sample_size-params$entry.end-1)), col="red", lwd=c(2))
abline(h = (4/(sample_size-params$entry.end-1)), col="red", lwd=c(3))
```


# Cleaned Models: {.tabset .tabset-fade}

## Outside Minimum IQR: {.tabset .tabset-fade}

Replaced all low values outside the minimum IQR value, as visualized in the barplot.

### Summary

Low yielding rows in which yield values were replaced with NA.

```{r modelc1, echo = FALSE}
##Replace All Low Values Identified in  Histogram (e.g.< IQR Minimum bu/ac) with NA:
IQRNoLow<-subset(data, data$yld < min.yld)
NoLowRows<-as.numeric(rownames(IQRNoLow))
NoLowRows
IQRClean1<-data
IQRClean1$yld<-replace(IQRClean1$yld, NoLowRows, NA)
##Model Without Histogram Identified Low Yields:
model2<-lmer(yld~entry + (1 | rep) + (1|rep:pass) + (1 | rep:range), data=IQRClean1, REML=TRUE)
```

**Summary**

```{r modelc1.sum2, echo=FALSE, message=FALSE}
summary(model2)
```

### Random-Effect Table

ANOVA-like table for random-effects: Single term deletions;

Model: yld ~ entry + (1 | rep) + (1 | rep:pass) + (1 | rep:range)

```{r modelc1.reml, echo=FALSE}
kable(ranova(model2))
```

### ANOVA Tables

Analysis of Variance Table of **Type I** with Kenward-Roger approximation for degrees of freedom:

```{r modelc1.anova1, echo=FALSE}
kable(anovalmer(model2))
```

**Type III** Analysis of Variance Table with Satterthwaite's method:

```{r modelc1.anova2, echo=FALSE}
kable(anova(model2))
```

### CV & LSD

**Coefficient of Vairance (CV):**

```{r, modelc1.cv, echo=FALSE}
LSDer::CVer(model2)
```

**Fisher's Least Significant Differnce (LSD):**

*At 90% Confidence:*

```{r, modelc1.lsd.1, echo=FALSE}
LSDer::LSDer(model2, "entry", level=0.95)
```

*At 75% Confidence:*

```{r, modelc1.lsd.25, echo=FALSE}
LSDer::LSDer(model2, "entry", level=0.75)
```

## Outside Min/Max IQRs: {.tabset .tabset-fade}

Replaced all values outside the minimum and maximum IQRs with NA, as visualized in the barplot.

### Summary

Low yielding, followed by high yielding rows in which yield values were replaced with NA.

```{r modelc2, echo = FALSE}
##Replace values outside the minimum and maximum IQR values with NA:
IQRNoHigh<-subset(data, data$yld > max.yld)
NoHighRows<-as.numeric(rownames(IQRNoHigh))
NoLowRows
NoHighRows
IQRClean2<-data
IQRClean2$yld<-replace(IQRClean2$yld, NoLowRows, NA)
IQRClean2$yld<-replace(IQRClean2$yld, NoHighRows, NA)
##Model Without Histogram Identified Low Yields:
model3<-lmer(yld~entry + (1 | rep) + (1|rep:pass) + (1 | rep:range), data=IQRClean2, REML=TRUE)
```

**Summary**

```{r modelc2.sum, echo=FALSE, message=FALSE}
summary(model3)
```

### Random-Effects Table

ANOVA-like table for random-effects: Single term deletions;

Model: yld ~ entry + (1 | rep) + (1 | rep:pass) + (1 | rep:range)

```{r modelc2.reml, echo=FALSE}
kable(ranova(model3))
```

### ANOVA Tables

Analysis of Variance Table of **Type I** with Kenward-Roger approximation for degrees of freedom:

```{r modelc2.1, echo=FALSE}
kable(anovalmer(model3))
```

**Type III** Analysis of Variance Table with Satterthwaite's method:

```{r modelc2.anova3, echo=FALSE}
kable(anova(model3))
```

### CV & LSD

**Coefficient of Vairance (CV):**

```{r modelc2.cv, echo=FALSE}
LSDer::CVer(model3)
```

**Fisher's Least Significant Differnce (LSD):**

*At 90% Confidence:*

```{r modelc2.lsd.1, echo=FALSE}
LSDer::LSDer(model3, "entry", level=0.90)
```

*At 75% Confidence:*

```{r modelc2.lsd.25, echo=FALSE}
LSDer::LSDer(model3, "entry", level=0.75)
```

## Residual Deviations: {.tabset .tabset-fade}

Replace residual outliers identified in  Q-Q Plot with NA for all resdiual values 2.5 times the standard deviation above/below the residual mean. 

### Summary

Influential residual deviating rows in which yield values were replaced with NA.

```{r modelc3, echo = FALSE}
# ##Replace All Residual Outliers 2.5 times the standard deviation above/below the 
# ##residual mean in  Q-Q Plot with NA:
influentialQQ<-resid(model1)[abs(resid(model1)-mean(resid(model1)))>2.5*sd(resid(model1))]
influentialQQ<-as.numeric(names(influentialQQ))
influentialQQ
QQClean<-data
QQClean$yld<-replace(QQClean$yld, influentialQQ, NA)
model4<-lmer(yld~entry + (1 | rep) + (1|rep:pass) + (1 | rep:range), data=QQClean, REML=TRUE)

# ##Alternatively, MUST designate trim = # of stddev above/below the residual means.
# ##Can NOT get to pull up "data" from romr Function.
# ResidualClean<-romr.fnc(model1, data, trim = 2.5)
# ResidualClean<-ResidualClean[["data"]]
# ##Model Without Q-Q Residual Outliers:
# model3<-lmer(yld~entry + (1 | rep) + (1|rep:pass) + (1 | rep:range), data=ResidualClean, REML=TRUE)
```

**Summary**

```{r modelc3.sum, echo=FALSE, message=FALSE}
summary(model4)
```

### Random-Effects Table

```{r modelc3.reml, echo=FALSE}
kable(ranova(model4))
```

### ANOVA Tables

Analysis of Variance Table of **Type I** with Kenward-Roger approximation for degrees of freedom:

```{r modelc3.anova1, echo=FALSE}
kable(anovalmer(model4))
```

**Type III** Analysis of Variance Table with Satterthwaite's method:

```{r modelc3.anova2, echo=FALSE}
kable(anova(model4))
```

### CV & LSD

**Coefficient of Vairance (CV):**

```{r modelc3.cv, echo=FALSE}
LSDer::CVer(model4)
```

**Fisher's Least Significant Differnce (LSD):**

*At 90% Confidence:*

```{r modelc3.lsd.1, echo=FALSE}
LSDer::LSDer(model4, "entry", level=0.90)
```

*At 75% Confidence:*

```{r modelc3.lsd.25, echo=FALSE}
LSDer::LSDer(model4, "entry", level=0.75)
```

## Cook's Distance: {.tabset .tabset-fade}

Replace influential Values determined Via Cook's Distance with NA.

-Cook' Distance outliers: **4/n-k-1**
-used: **10/n-k-1** 
-[i.e. 2.5 x Cook's Distance Significance]

### Summary

Influential Cook's Distance rows in which yield values were replaced with NA.

```{r modelc4, echo = FALSE}
##Replace "Influential" Values Determined Via Cook's Distance, with NA:
influentialcooks <- as.numeric(names(Cooksd)[(Cooksd > (h=(10/(sample_size-params$entry.end-1))))])
influentialcooks
CooksClean<-data
CooksClean$yld<-replace(CooksClean$yld, influentialcooks, NA)
##Cooks Clean Model:
model5<-lmer(yld~entry + (1 | rep) + (1|rep:pass) + (1 | rep:range), data=CooksClean, REML=TRUE)
```

**Summary**

```{r modelc4.sum, echo=FALSE, message=FALSE}
summary(model5)
```

### Random-Effects Table

```{r modelc4.reml, echo=FALSE}
kable(ranova(model5))
```

### ANOVA Tables

Analysis of Variance Table of **Type I** with Kenward-Roger approximation for degrees of freedom:

```{r modelc4.anova1, echo=FALSE}
kable(anovalmer(model5))
```

**Type III** Analysis of Variance Table with Satterthwaite's method:

```{r modelc4.anova2, echo=FALSE}
kable(anova(model5))
```

### CV & LSD

**Coefficient of Vairance (CV):**

```{r modelc4.cv, echo=FALSE}
LSDer::CVer(model5)
```

**Fisher's Least Significant Differnce (LSD):**

*At 90% Confidence:*

```{r modelc4.lsd.1, echo=FALSE}
LSDer::LSDer(model5, "entry", level=0.90)
```

*At 75% Confidence:*

```{r modelc4.lsd.25, echo=FALSE}
LSDer::LSDer(model5, "entry", level=0.75)
```

# Export Clean Dataset: {.tabset .tabset-fade}

```{r export, echo = FALSE}
# write.csv(CooksClean, "C:/Users/rjbudnik/Desktop/R_Cleaned/CooksClean_CF811_C81A.csv")
# write.csv(QQClean, "C:/Users/rjbudnik/Desktop/R_Cleaned/QQClean_CF811_C81A.csv")
# write.csv(HistoClean, "C:/Users/rjbudnik/Desktop/R_Cleaned/HistoClean_CF811_C81A.csv")
# write.csv(ResidualClean, "C:/Users/rjbudnik/Desktop/R_Cleaned/ResidualClean_CF811_C81A.csv")
```

# References:
1. **Hair, J., Anderson, R., Tatham, R. and Black W.** (1998). Multivariate Data Analysis (fifth edition). Englewood Cliffs, NJ: Prentice-Hall.
